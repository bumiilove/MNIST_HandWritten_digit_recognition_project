{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SsITgjhPQvh0"
      },
      "outputs": [],
      "source": [
        "import numpy as np # 선형대수 모듈\n",
        "import matplotlib.pyplot as plt # 시각화 모듈\n",
        "import torch # 파이토치\n",
        "import torch.nn as nn # PyTorch의 모듈을 모아놓은 것. from~~이 아닌 저렇게 임포트를 하는 것이 거의 관습이라고 한다.\n",
        "import torch.nn.functional as F # torch.nn 중에서 자주 쓰는 함수를 F로 임포트.\n",
        "import torch.nn.init as init # 초기화 관련 모듈 \n",
        "import torchvision # TorchVision 임포트\n",
        "from torchvision import transforms, datasets # 데이터를 다루기 위한 TorchVision 내의 Transforms와 datasets를 따로 임포트\n",
        "from collections import OrderedDict\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFeF4A2XQ0lc",
        "outputId": "af2b1c08-c458-42a8-f5ad-3dc90de340e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using PyTorch version:  1.13.0 Device:  cpu\n"
          ]
        }
      ],
      "source": [
        "DEVICE = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 30\n",
        "\n",
        "print('Using PyTorch version: ', torch.__version__, 'Device: ', DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "L7DQoI_0Q7EX"
      },
      "outputs": [],
      "source": [
        "train_dataset = datasets.MNIST(\n",
        "    root=\"../data/MNIST\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor()\n",
        ")\n",
        "test_dataset = datasets.MNIST(\n",
        "    root=\"../data/MNIST\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor()\n",
        ")\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwbU7r9qiCES",
        "outputId": "ec396ac4-fbaa-4a55-958e-2e97170acae6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3294, 0.7255,\n",
              "           0.6235, 0.5922, 0.2353, 0.1412, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8706, 0.9961,\n",
              "           0.9961, 0.9961, 0.9961, 0.9451, 0.7765, 0.7765, 0.7765, 0.7765,\n",
              "           0.7765, 0.7765, 0.7765, 0.7765, 0.6667, 0.2039, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2627, 0.4471,\n",
              "           0.2824, 0.4471, 0.6392, 0.8902, 0.9961, 0.8824, 0.9961, 0.9961,\n",
              "           0.9961, 0.9804, 0.8980, 0.9961, 0.9961, 0.5490, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0667, 0.2588, 0.0549, 0.2627, 0.2627,\n",
              "           0.2627, 0.2314, 0.0824, 0.9255, 0.9961, 0.4157, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.3255, 0.9922, 0.8196, 0.0706, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0863, 0.9137, 1.0000, 0.3255, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.5059, 0.9961, 0.9333, 0.1725, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.2314, 0.9765, 0.9961, 0.2431, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.5216, 0.9961, 0.7333, 0.0196, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0353,\n",
              "           0.8039, 0.9725, 0.2275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4941,\n",
              "           0.9961, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2941, 0.9843,\n",
              "           0.9412, 0.2235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0745, 0.8667, 0.9961,\n",
              "           0.6510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.7961, 0.9961, 0.8588,\n",
              "           0.1373, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.1490, 0.9961, 0.9961, 0.3020,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.1216, 0.8784, 0.9961, 0.4510, 0.0039,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.5216, 0.9961, 0.9961, 0.2039, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.2392, 0.9490, 0.9961, 0.9961, 0.2039, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.4745, 0.9961, 0.9961, 0.8588, 0.1569, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.4745, 0.9961, 0.8118, 0.0706, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
              " 7)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeXZOiXxQ-85",
        "outputId": "68d94941-c998-4dbf-fbaa-d6b230bbf38c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train:  torch.Size([32, 1, 28, 28]) type:  torch.FloatTensor\n",
            "y_train:  torch.Size([32]) type:  torch.LongTensor\n"
          ]
        }
      ],
      "source": [
        "for (X_train, y_train) in train_loader:\n",
        "    print('X_train: ', X_train.size(), 'type: ', X_train.type())\n",
        "    print('y_train: ', y_train.size(), 'type: ', y_train.type())\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aGi_zsy0RCDK"
      },
      "outputs": [],
      "source": [
        "layer1_in=28*28\n",
        "layer1_out=32\n",
        "layer2_in=32\n",
        "layer2_out=16\n",
        "layer3_in=16\n",
        "layer3_out=10\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(layer1_in, layer1_out)\n",
        "        self.fc2 = nn.Linear(layer2_in, layer2_out)\n",
        "        self.fc3 = nn.Linear(layer3_in, layer3_out)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x) # sigmoid(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x) # sigmoid(x)\n",
        "        x = self.fc3(x)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "z8t_sJXYRHj2"
      },
      "outputs": [],
      "source": [
        "def weight_init(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        init.kaiming_uniform_(m.weight.data)\n",
        "\n",
        "model = MLP().to(DEVICE) # 정의한 모델을 GPU로 납치\n",
        "model.apply(weight_init)\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SAfciT2fRMxt"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, optimizer, log_interval):\n",
        "    model.train()\n",
        "    for batch_idx, (image, label) in enumerate(train_loader):\n",
        "        image = image.to(DEVICE)\n",
        "        label = label.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(image)\n",
        "        loss = loss_fn(output, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_8JsSKiHRc0X"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for image, label in test_loader:\n",
        "            image = image.to(DEVICE)\n",
        "            label = label.to(DEVICE)\n",
        "            output = model(image)\n",
        "            test_loss += loss_fn(output, label).item()\n",
        "            prediction = output.max(1, keepdim=True)[1]\n",
        "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
        "    \n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    return test_loss, test_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aaJ0lW5ReXf",
        "outputId": "801c3980-2fff-4b1c-cec9-e1fc3327d05a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[EPOCH: 1], \tTest Loss: 0.0066, \tTest Accuracy: 93.99 %\n",
            "[EPOCH: 2], \tTest Loss: 0.0065, \tTest Accuracy: 93.93 %\n",
            "[EPOCH: 3], \tTest Loss: 0.0075, \tTest Accuracy: 93.68 %\n",
            "[EPOCH: 4], \tTest Loss: 0.0065, \tTest Accuracy: 94.18 %\n",
            "[EPOCH: 5], \tTest Loss: 0.0057, \tTest Accuracy: 95.14 %\n",
            "[EPOCH: 6], \tTest Loss: 0.0059, \tTest Accuracy: 95.03 %\n",
            "[EPOCH: 7], \tTest Loss: 0.0060, \tTest Accuracy: 95.29 %\n",
            "[EPOCH: 8], \tTest Loss: 0.0071, \tTest Accuracy: 94.71 %\n",
            "[EPOCH: 9], \tTest Loss: 0.0064, \tTest Accuracy: 94.94 %\n",
            "[EPOCH: 10], \tTest Loss: 0.0050, \tTest Accuracy: 96.02 %\n",
            "[EPOCH: 11], \tTest Loss: 0.0055, \tTest Accuracy: 95.87 %\n",
            "[EPOCH: 12], \tTest Loss: 0.0064, \tTest Accuracy: 95.43 %\n",
            "[EPOCH: 13], \tTest Loss: 0.0058, \tTest Accuracy: 95.68 %\n",
            "[EPOCH: 14], \tTest Loss: 0.0058, \tTest Accuracy: 95.66 %\n",
            "[EPOCH: 15], \tTest Loss: 0.0053, \tTest Accuracy: 96.24 %\n",
            "[EPOCH: 16], \tTest Loss: 0.0064, \tTest Accuracy: 95.30 %\n",
            "[EPOCH: 17], \tTest Loss: 0.0057, \tTest Accuracy: 96.20 %\n",
            "[EPOCH: 18], \tTest Loss: 0.0065, \tTest Accuracy: 95.58 %\n",
            "[EPOCH: 19], \tTest Loss: 0.0061, \tTest Accuracy: 95.79 %\n",
            "[EPOCH: 20], \tTest Loss: 0.0063, \tTest Accuracy: 95.93 %\n",
            "[EPOCH: 21], \tTest Loss: 0.0062, \tTest Accuracy: 95.81 %\n",
            "[EPOCH: 22], \tTest Loss: 0.0072, \tTest Accuracy: 95.78 %\n",
            "[EPOCH: 23], \tTest Loss: 0.0066, \tTest Accuracy: 95.50 %\n",
            "[EPOCH: 24], \tTest Loss: 0.0084, \tTest Accuracy: 95.16 %\n",
            "[EPOCH: 25], \tTest Loss: 0.0068, \tTest Accuracy: 95.76 %\n",
            "[EPOCH: 26], \tTest Loss: 0.0072, \tTest Accuracy: 95.69 %\n",
            "[EPOCH: 27], \tTest Loss: 0.0067, \tTest Accuracy: 95.94 %\n",
            "[EPOCH: 28], \tTest Loss: 0.0083, \tTest Accuracy: 95.41 %\n",
            "[EPOCH: 29], \tTest Loss: 0.0083, \tTest Accuracy: 95.75 %\n",
            "[EPOCH: 30], \tTest Loss: 0.0079, \tTest Accuracy: 95.90 %\n"
          ]
        }
      ],
      "source": [
        "max_test_accuracy=0\n",
        "w1_name=\"float w1[\"+str(layer1_out)+\"][\"+str(layer1_in)+\"] = { { \"\n",
        "b1_name=\"float b1[\"+str(layer1_out)+\"] = { \"\n",
        "w2_name=\"float w2[\"+str(layer2_out)+\"][\"+str(layer2_in)+\"] = { { \"\n",
        "b2_name=\"float b2[\"+str(layer2_out)+\"] = { \"\n",
        "w3_name=\"float w3[\"+str(layer3_out)+\"][\"+str(layer3_in)+\"] = { { \"\n",
        "b3_name=\"float b3[\"+str(layer3_out)+\"] = { \"\n",
        "for Epoch in range(1, EPOCHS + 1):\n",
        "    train(model, train_loader, optimizer, log_interval=100)\n",
        "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
        "    print(\"[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} %\".format(\n",
        "        Epoch, test_loss, test_accuracy\n",
        "    ))\n",
        "    if test_accuracy>max_test_accuracy:\n",
        "      max_test_accuracy=test_accuracy\n",
        "      acc=str(max_test_accuracy)\n",
        "      PATH = \"MLP_\"+str(layer2_in)+\"_\"+str(layer3_in)+\"_\"+acc+\"_\"+str(Epoch)+\".pt\"\n",
        "      torch.save(model.state_dict(), PATH)\n",
        "      model_verb_cpu = model.eval()\n",
        "      od1 = model_verb_cpu.state_dict()\n",
        "      od1 = OrderedDict({k: od1[k].detach().cpu().tolist() for k in od1})\n",
        "      od1 = json.dumps(od1)\n",
        "      w1=str(od1.split('fc1.weight\": [[')[1]).split(\"]]\")[0]\n",
        "      w1=w1.replace('[','{')\n",
        "      w1=w1.replace(']','}')\n",
        "      b1=str(od1.split('fc1.bias\": [')[1]).split(']')[0]\n",
        "      w2=str(od1.split('fc2.weight\": [[')[1]).split(\"]]\")[0]\n",
        "      w2=w2.replace('[','{')\n",
        "      w2=w2.replace(']','}')\n",
        "      b2=str(od1.split('fc2.bias\": [')[1]).split(']')[0]\n",
        "      w3=str(od1.split('fc3.weight\": [[')[1]).split(\"]]\")[0]\n",
        "      w3=w3.replace('[','{')\n",
        "      w3=w3.replace(']','}')\n",
        "      b3=str(od1.split('fc3.bias\": [')[1]).split(']')[0]\n",
        "      with open(\"MLP_\"+str(layer2_in)+\"_\"+str(layer3_in)+\"_\"+acc+\"_\"+str(Epoch)+\".h\", 'w') as outfile:\n",
        "          outfile.write(w1_name)\n",
        "          outfile.write(w1)\n",
        "          outfile.write(\"} };\\n\")\n",
        "          outfile.write(b1_name)\n",
        "          outfile.write(b1)\n",
        "          outfile.write(\"};\\n\")\n",
        "          outfile.write(w2_name)\n",
        "          outfile.write(w2)\n",
        "          outfile.write(\"} };\\n\")\n",
        "          outfile.write(b2_name)\n",
        "          outfile.write(b2)\n",
        "          outfile.write(\"};\\n\")\n",
        "          outfile.write(w3_name)\n",
        "          outfile.write(w3)\n",
        "          outfile.write(\"} };\\n\")\n",
        "          outfile.write(b3_name)\n",
        "          outfile.write(b3)\n",
        "          outfile.write(\"};\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
